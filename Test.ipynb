{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62408b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division, print_function, unicode_literals\n",
    "from tika import parser\n",
    "import easygui\n",
    "import re\n",
    "\n",
    "from sumy.parsers.html import HtmlParser\n",
    "from sumy.parsers.plaintext import PlaintextParser\n",
    "from sumy.nlp.tokenizers import Tokenizer\n",
    "from sumy.summarizers.lsa import LsaSummarizer as Summarizer\n",
    "from sumy.nlp.stemmers import Stemmer\n",
    "from sumy.utils import get_stop_words\n",
    "\n",
    "\n",
    "LANGUAGE = \"english\"\n",
    "SENTENCES_COUNT = 15\n",
    "\n",
    "def initial_match(filename):\n",
    "    number_pattern = re.compile(\"^\\d+\\..*$\")\n",
    "    link_pattern = re.compile(\"^http://.*$\")\n",
    "    doi_pattern = re.compile(\"^.*(doi|DOI):.*$\")\n",
    "    header_pattern = re.compile(\"^.*(Citation|Funding):.*$\")\n",
    "    edited_output = []\n",
    "    with open(filename) as f:\n",
    "        for line in f:\n",
    "            if not number_pattern.match(line) \\\n",
    "            and not link_pattern.match(line) \\\n",
    "            and not doi_pattern.match(line) \\\n",
    "            and not header_pattern.match(line) \\\n",
    "            and line not in ['\\n', '\\r\\n']:\n",
    "                edited_output.append(line)\n",
    "            else:\n",
    "                print(\"matched line: %s\" % line)\n",
    "    return edited_output\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    path = easygui.fileopenbox()\n",
    "    raw = parser.from_file(path)\n",
    "\n",
    "    with open(\"output.txt\", \"w\") as text_file:\n",
    "        text_file.write(raw['content'])\n",
    "\n",
    "    edited_output = initial_match(\"output.txt\")\n",
    "\n",
    "    with open(\"output.txt\", \"w\") as f:\n",
    "        f.writelines(edited_output)\n",
    "\n",
    "\n",
    "\n",
    "    # url = \"https://en.wikipedia.org/wiki/Frances_Ivens\"\n",
    "    # parser = HtmlParser.from_url(url, Tokenizer(LANGUAGE))\n",
    "    # or for plain text files\n",
    "    parser = PlaintextParser.from_file(\"output.txt\", Tokenizer(LANGUAGE))\n",
    "    stemmer = Stemmer(LANGUAGE)\n",
    "    summarizer = Summarizer(stemmer)\n",
    "    summarizer.stop_words = get_stop_words(LANGUAGE)\n",
    "\n",
    "    with open('final.txt', 'w') as f:\n",
    "        for sentence in summarizer(parser.document, SENTENCES_COUNT):\n",
    "            f.write(\"%s \\n\" % str(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560f6608",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division, print_function, unicode_literals\n",
    "from tika import parser\n",
    "import easygui\n",
    "import re\n",
    "\n",
    "from sumy.parsers.html import HtmlParser\n",
    "from sumy.parsers.plaintext import PlaintextParser\n",
    "from sumy.nlp.tokenizers import Tokenizer\n",
    "from sumy.summarizers.lsa import LsaSummarizer as Summarizer\n",
    "from sumy.nlp.stemmers import Stemmer\n",
    "from sumy.utils import get_stop_words\n",
    "\n",
    "\n",
    "LANGUAGE = \"english\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723357c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initial_match(filename):\n",
    "    number_pattern = re.compile(\"^\\d+\\..*$\")\n",
    "    link_pattern = re.compile(\"^http://.*$\")\n",
    "    doi_pattern = re.compile(\"^.*(doi|DOI):.*$\")\n",
    "    header_pattern = re.compile(\"^.*(Citation|Funding):.*$\")\n",
    "    edited_output = []\n",
    "    with open(filename) as f:\n",
    "        for line in f:\n",
    "            if not number_pattern.match(line) \\\n",
    "            and not link_pattern.match(line) \\\n",
    "            and not doi_pattern.match(line) \\\n",
    "            and not header_pattern.match(line) \\\n",
    "            and line not in ['\\n', '\\r\\n']:\n",
    "                edited_output.append(line)\n",
    "            else:\n",
    "                print(\"matched line: %s\" % line)\n",
    "    return edited_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e743e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = easygui.fileopenbox()\n",
    "    raw = parser.from_file(path)\n",
    "\n",
    "    with open(\"output.txt\", \"w\") as text_file:\n",
    "        text_file.write(raw['content'])\n",
    "\n",
    "    edited_output = initial_match(\"output.txt\")\n",
    "\n",
    "    with open(\"output.txt\", \"w\") as f:\n",
    "        f.writelines(edited_output)\n",
    "\n",
    "\n",
    "\n",
    "    # url = \"https://en.wikipedia.org/wiki/Frances_Ivens\"\n",
    "    # parser = HtmlParser.from_url(url, Tokenizer(LANGUAGE))\n",
    "    # or for plain text files\n",
    "    parser = PlaintextParser.from_file(\"output.txt\", Tokenizer(LANGUAGE))\n",
    "    stemmer = Stemmer(LANGUAGE)\n",
    "    summarizer = Summarizer(stemmer)\n",
    "    summarizer.stop_words = get_stop_words(LANGUAGE)\n",
    "\n",
    "    with open('final.txt', 'w') as f:\n",
    "        for sentence in summarizer(parser.document, SENTENCES_COUNT):\n",
    "            f.write(\"%s \\n\" % str(sentence))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
